# Multi-VM Distributed Training Configuration
#
# This config demonstrates training across multiple VMs with load balancing.
# Useful for scaling up data collection with ActorPoolManager.

experiment_name: "qwen25_vl_multi_vm"

model:
  name: "Qwen/Qwen2.5-VL-3B-Instruct"
  device: "cuda"
  torch_dtype: "float16"

  use_lora: true
  lora_target_option: "attention+mlp"
  lora_rank: 32
  lora_alpha: 32
  lora_dropout: 0.05
  lora_bias: "none"

  max_new_tokens: 128
  temperature: 0.7
  do_sample: true
  freeze_vision_encoder: false

trainer:
  batch_size: 32  # Larger batch with more VMs
  learning_rate: null
  num_training_steps: 500
  save_every: 25
  queue_timeout: 10.0  # Longer timeout with more actors
  algorithm: "rejection_sampling"
  reward_threshold: 0.0

actor:
  max_steps_per_episode: 50
  action_format: "json"
  screenshot_size: [224, 224]
  task_prompt: "Complete the data entry task"
  session_type: "simple_data_entry"
  action_delay: 1.0
  data_dir: "experiments/qwen25_vl_multi_vm/trajectories"  # Save trajectories for analysis

actor_pool:
  target_concurrent_actors: 8  # 2 actors per VM * 4 VMs
  max_concurrent_per_vm: 2  # Memory limit per VM
  monitor_interval: 2.0

environment:
  # Multiple VMs for distributed data collection
  # ActorPoolManager will load balance across these VMs
  vm_urls:
    - "http://vm-1.example.com:8000"
    - "http://vm-2.example.com:8000"
    - "http://vm-3.example.com:8000"
    - "http://vm-4.example.com:8000"
  timeout: 30
  max_retries: 3

logging:
  log_level: "INFO"
  log_dir: "experiments/qwen25_vl_multi_vm/logs"
  checkpoint_dir: "experiments/qwen25_vl_multi_vm/checkpoints"
  trajectory_dir: "experiments/qwen25_vl_multi_vm/trajectories"  # Save trajectories
  verbose: false
